{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéôÔ∏è PodcastGen with Indic Parler TTS\n",
                "\n",
                "Generate AI podcasts with high-quality Indian language TTS!\n",
                "\n",
                "---\n",
                "## ‚ö†Ô∏è Enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Clone & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "!git clone https://github.com/beginner4a3/hela.git\n",
                "%cd hela\n",
                "\n",
                "# Set HuggingFace token (get yours at https://huggingface.co/settings/tokens)\n",
                "import os\n",
                "os.environ['HF_TOKEN'] = \"YOUR_HF_TOKEN_HERE\"  # <-- Replace with your actual token\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -q pydub google-genai pydantic==2.10.6 aiofiles soundfile\n",
                "!pip install -q git+https://github.com/huggingface/parler-tts.git\n",
                "!pip install -q torch transformers huggingface_hub gradio nest_asyncio\n",
                "!apt-get install -y ffmpeg > /dev/null 2>&1\n",
                "\n",
                "print(\"\\n‚úÖ Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Launch App\n",
                "\n",
                "All progress updates and errors will be printed below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/hela')\n",
                "\n",
                "import torch\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None - enable GPU!'}\")\n",
                "\n",
                "from app import load_tts_model, main\n",
                "\n",
                "# Load TTS model\n",
                "load_tts_model()\n",
                "\n",
                "# Launch Gradio interface (debug=True shows errors in this cell)\n",
                "main(debug=True)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}